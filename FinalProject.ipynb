{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d4d43-6d1b-4d35-aa02-56670fcbfc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe4987-1045-464d-a035-e7c4781b650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8933896c-b59e-4461-84d0-ce9c28c5de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e123211d-8971-4d8d-83e7-c04279d6ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0b8147-7c49-4c42-a382-bcc83f86fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b22eaf6-5467-4e59-98a5-3c2d58f26b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce4b949-efc1-4db8-9f64-b33db3bad529",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fc90c7e-4a8d-419f-a7bf-c4fd630f91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINE_COLOR = (0, 255, 0)  # Green for lines\n",
    "DOT_COLOR = (0, 0, 255)   # Red for dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73dc37db-b9a6-4125-b1d9-70b8084300b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACE_POINTS = [\n",
    "    33, 133, 362, 263, 1, 9, 61, 291, 13, 14, 234, 454, 168, 93, 323, \n",
    "    199, 175, 152, 21, 22, 206, 426, 405, 18, 287, 10, 57, 287, 314,\n",
    "    17, 18, 122, 351, 11  # Additional points including cheeks and jawline\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77ea58c7-ef83-4cda-917c-5b376fde8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_raised_fingers(hand_landmarks):\n",
    "    fingers = []\n",
    "    \n",
    "    # Thumb: Check if it's raised.\n",
    "    if hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].x < hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_IP].x:\n",
    "        fingers.append(1)  # Thumb raised\n",
    "    else:\n",
    "        fingers.append(0)  # Thumb down\n",
    "    \n",
    "    # Other fingers: Check if each fingertip is higher than its PIP.\n",
    "    for i in range(1, 5):  # Index to Pinky\n",
    "        if hand_landmarks.landmark[mp_hands.HandLandmark(i * 4)].y < hand_landmarks.landmark[mp_hands.HandLandmark(i * 4 - 2)].y:\n",
    "            fingers.append(1)  # Finger raised\n",
    "        else:\n",
    "            fingers.append(0)  # Finger down\n",
    "            \n",
    "    return fingers.count(1)  # Count raised fingers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "245f6b43-bd57-4f72-b85e-49b81bbdbcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hand_gesture_text(raised_fingers):\n",
    "    gestures = {\n",
    "        1: \"approval\",\n",
    "        2: \"victory\",\n",
    "        3: \"shocker\",\n",
    "        4: \"number 4\",\n",
    "        5: \"hello\"\n",
    "        \n",
    "    }\n",
    "    return gestures.get(raised_fingers, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbf95f85-a58c-4361-b4e2-c69552e0bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mouth_open(face_landmarks):\n",
    "    mouth_top = face_landmarks.landmark[13].y  # Upper lip point\n",
    "    mouth_bottom = face_landmarks.landmark[14].y  # Lower lip point\n",
    "    return (mouth_bottom - mouth_top) > 0.04  # Threshold for mouth opening\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a739cdc-37c4-4c34-a85b-730ee6384bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hand_landmarks_custom(image, hand_landmarks):\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        hand_landmarks,\n",
    "        mp_hands.HAND_CONNECTIONS,\n",
    "        mp_drawing.DrawingSpec(color=LINE_COLOR, thickness=1, circle_radius=2),\n",
    "        mp_drawing.DrawingSpec(color=DOT_COLOR, thickness=3)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52b8a912-3e10-4725-8cc4-eb2ea8042b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_face_mesh_custom(image, face_landmarks):\n",
    "    for i in range(len(FACE_POINTS) - 1):\n",
    "        start = face_landmarks.landmark[FACE_POINTS[i]]\n",
    "        end = face_landmarks.landmark[FACE_POINTS[i + 1]]\n",
    "        start_point = (int(start.x * image.shape[1]), int(start.y * image.shape[0]))\n",
    "        end_point = (int(end.x * image.shape[1]), int(end.y * image.shape[0]))\n",
    "        cv2.line(image, start_point, end_point, LINE_COLOR, 1)\n",
    "    \n",
    "    # Draw each of the selected face points as small red dots\n",
    "    for idx in FACE_POINTS:\n",
    "        point = face_landmarks.landmark[idx]\n",
    "        point_coords = (int(point.x * image.shape[1]), int(point.y * image.shape[0]))\n",
    "        cv2.circle(image, point_coords, 2, DOT_COLOR, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca122b0e-5062-42b2-bc08-80b162468fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_text_with_box(image, text, position, box_color=(50, 50, 50), text_color=(255, 255, 255)):\n",
    "    (text_width, text_height), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    box_coords = ((position[0] - 10, position[1] - 40), (position[0] + text_width + 10, position[1] + text_height - 10))\n",
    "    cv2.rectangle(image, box_coords[0], box_coords[1], box_color, cv2.FILLED)\n",
    "    cv2.putText(image, text, position, cv2.FONT_HERSHEY_SIMPLEX, 1, text_color, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6141de-798a-460b-907b-fb8c863a1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands, \\\n",
    "     mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5) as face_mesh, \\\n",
    "     mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Flip the image horizontally for a mirror effect.\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Convert the color space from BGR to RGB.\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the frame for hands, face mesh, and pose for shoulders.\n",
    "        hand_results = hands.process(rgb_frame)\n",
    "        face_results = face_mesh.process(rgb_frame)\n",
    "        pose_results = pose.process(rgb_frame)\n",
    "        \n",
    "        total_raised_fingers = 0\n",
    "        mouth_open = False\n",
    "        \n",
    "        # Draw face landmarks if detected.\n",
    "        if face_results.multi_face_landmarks:\n",
    "            for face_landmarks in face_results.multi_face_landmarks:\n",
    "                draw_face_mesh_custom(frame, face_landmarks)\n",
    "                mouth_open = is_mouth_open(face_landmarks)\n",
    "        \n",
    "        # Draw hand landmarks and count raised fingers if hands are present.\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                draw_hand_landmarks_custom(frame, hand_landmarks)\n",
    "                \n",
    "                # Count raised fingers for each hand.\n",
    "                raised_fingers = count_raised_fingers(hand_landmarks)\n",
    "                total_raised_fingers += raised_fingers\n",
    "        \n",
    "        # Display gesture based on total raised fingers.\n",
    "        sign_text = get_hand_gesture_text(total_raised_fingers)\n",
    "        \n",
    "        if sign_text:\n",
    "            display_text_with_box(frame, sign_text, (20, 65), box_color=(50, 50, 50), text_color=(255, 255, 255))\n",
    "        \n",
    "        # Display \"How it is going\" if mouth is open.\n",
    "        if mouth_open:\n",
    "            display_text_with_box(frame, \"How it is going\", (300, 65), box_color=(0, 128, 0), text_color=(0, 255, 0))\n",
    "\n",
    "        # Draw shoulder points if pose detected.\n",
    "        if pose_results.pose_landmarks:\n",
    "            left_shoulder = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "            right_shoulder = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "            left_shoulder_coords = (int(left_shoulder.x * frame.shape[1]), int(left_shoulder.y * frame.shape[0]))\n",
    "            right_shoulder_coords = (int(right_shoulder.x * frame.shape[1]), int(right_shoulder.y * frame.shape[0]))\n",
    "            \n",
    "            # Draw shoulder points as red dots.\n",
    "            cv2.circle(frame, left_shoulder_coords, 4, DOT_COLOR, -1)\n",
    "            cv2.circle(frame, right_shoulder_coords, 4, DOT_COLOR, -1)\n",
    "            cv2.line(frame, left_shoulder_coords, right_shoulder_coords, LINE_COLOR, 1)\n",
    "        \n",
    "        # Display the final frame.\n",
    "        cv2.imshow(\"Enhanced Hand, Face, and Shoulder Tracking\", frame)\n",
    "        \n",
    "        # Exit on pressing 'q'.\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6784b5-862d-4b52-8e99-f5341b2cbdec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389762e6-7b17-4d3d-a102-3c4d8d412b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c38f7-0ee1-4719-8f1d-6f637558eb8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackKernel",
   "language": "python",
   "name": "hackkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
