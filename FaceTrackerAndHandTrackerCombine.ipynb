{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd815cc-f7e3-4144-9647-131f06df56a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89c0001-ac32-4def-b2a1-3858cbb445ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hands and Face Mesh for face and shoulder tracking.\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Define colors for lines and dots.\n",
    "LINE_COLOR = (0, 255, 0)  # Green for lines\n",
    "DOT_COLOR = (0, 0, 255)   # Red for dots\n",
    "\n",
    "# Extended facial points for a highly detailed look.\n",
    "FACE_POINTS = [\n",
    "    33, 133, 362, 263, 1, 9, 61, 291, 13, 14, 234, 454, 168, 93, 323, \n",
    "    199, 175, 152, 21, 22, 206, 426, 405, 18, 287, 10, 57, 287, 314,\n",
    "    17, 18, 122, 351, 11  # Additional points including cheeks and jawline\n",
    "]\n",
    "\n",
    "# Function to count raised fingers.\n",
    "def count_raised_fingers(hand_landmarks):\n",
    "    fingers = []\n",
    "    \n",
    "    # Thumb: Check if it's raised.\n",
    "    if hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].x < hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_IP].x:\n",
    "        fingers.append(1)  # Thumb raised\n",
    "    else:\n",
    "        fingers.append(0)  # Thumb down\n",
    "    \n",
    "    # Other fingers: Check if each fingertip is higher than its PIP.\n",
    "    for i in range(1, 5):  # Index to Pinky\n",
    "        if hand_landmarks.landmark[mp_hands.HandLandmark(i * 4)].y < hand_landmarks.landmark[mp_hands.HandLandmark(i * 4 - 2)].y:\n",
    "            fingers.append(1)  # Finger raised\n",
    "        else:\n",
    "            fingers.append(0)  # Finger down\n",
    "            \n",
    "    return fingers.count(1)  # Count raised fingers\n",
    "\n",
    "# Function to get hand gesture text.\n",
    "def get_hand_gesture_text(raised_fingers):\n",
    "    gestures = {\n",
    "        1: \"Hello\",\n",
    "        2: \"Hi\",\n",
    "        3: \"Bye\",\n",
    "        4: \"No\",\n",
    "        5: \"Yes\"\n",
    "    }\n",
    "    return gestures.get(raised_fingers, \"\")\n",
    "\n",
    "# Function to check if mouth is open.\n",
    "def is_mouth_open(face_landmarks):\n",
    "    mouth_top = face_landmarks.landmark[13].y  # Upper lip point\n",
    "    mouth_bottom = face_landmarks.landmark[14].y  # Lower lip point\n",
    "    return (mouth_bottom - mouth_top) > 0.04  # Threshold for mouth opening\n",
    "\n",
    "# Function to draw hand landmarks with thin green and red lines.\n",
    "def draw_hand_landmarks_custom(image, hand_landmarks):\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        hand_landmarks,\n",
    "        mp_hands.HAND_CONNECTIONS,\n",
    "        mp_drawing.DrawingSpec(color=LINE_COLOR, thickness=1, circle_radius=2),\n",
    "        mp_drawing.DrawingSpec(color=DOT_COLOR, thickness=3)\n",
    "    )\n",
    "\n",
    "# Function to draw a technical face mesh with selected points and lines.\n",
    "def draw_face_mesh_custom(image, face_landmarks):\n",
    "    for i in range(len(FACE_POINTS) - 1):\n",
    "        start = face_landmarks.landmark[FACE_POINTS[i]]\n",
    "        end = face_landmarks.landmark[FACE_POINTS[i + 1]]\n",
    "        start_point = (int(start.x * image.shape[1]), int(start.y * image.shape[0]))\n",
    "        end_point = (int(end.x * image.shape[1]), int(end.y * image.shape[0]))\n",
    "        cv2.line(image, start_point, end_point, LINE_COLOR, 1)\n",
    "    \n",
    "    # Draw each of the selected face points as small red dots\n",
    "    for idx in FACE_POINTS:\n",
    "        point = face_landmarks.landmark[idx]\n",
    "        point_coords = (int(point.x * image.shape[1]), int(point.y * image.shape[0]))\n",
    "        cv2.circle(image, point_coords, 2, DOT_COLOR, -1)\n",
    "\n",
    "# Function to display text with a styled box.\n",
    "def display_text_with_box(image, text, position, box_color=(50, 50, 50), text_color=(255, 255, 255)):\n",
    "    (text_width, text_height), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    box_coords = ((position[0] - 10, position[1] - 40), (position[0] + text_width + 10, position[1] + text_height - 10))\n",
    "    cv2.rectangle(image, box_coords[0], box_coords[1], box_color, cv2.FILLED)\n",
    "    cv2.putText(image, text, position, cv2.FONT_HERSHEY_SIMPLEX, 1, text_color, 2)\n",
    "\n",
    "# Start webcam and process frames.\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands, \\\n",
    "     mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5) as face_mesh, \\\n",
    "     mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Flip the image horizontally for a mirror effect.\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Convert the color space from BGR to RGB.\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the frame for hands, face mesh, and pose for shoulders.\n",
    "        hand_results = hands.process(rgb_frame)\n",
    "        face_results = face_mesh.process(rgb_frame)\n",
    "        pose_results = pose.process(rgb_frame)\n",
    "        \n",
    "        total_raised_fingers = 0\n",
    "        mouth_open = False\n",
    "        \n",
    "        # Draw face landmarks if detected.\n",
    "        if face_results.multi_face_landmarks:\n",
    "            for face_landmarks in face_results.multi_face_landmarks:\n",
    "                draw_face_mesh_custom(frame, face_landmarks)\n",
    "                mouth_open = is_mouth_open(face_landmarks)\n",
    "        \n",
    "        # Draw hand landmarks and count raised fingers if hands are present.\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                draw_hand_landmarks_custom(frame, hand_landmarks)\n",
    "                \n",
    "                # Count raised fingers for each hand.\n",
    "                raised_fingers = count_raised_fingers(hand_landmarks)\n",
    "                total_raised_fingers += raised_fingers\n",
    "        \n",
    "        # Display gesture based on total raised fingers.\n",
    "        sign_text = get_hand_gesture_text(total_raised_fingers)\n",
    "        \n",
    "        if sign_text:\n",
    "            display_text_with_box(frame, sign_text, (20, 65), box_color=(50, 50, 50), text_color=(255, 255, 255))\n",
    "        \n",
    "        # Display \"How it is going\" if mouth is open.\n",
    "        if mouth_open:\n",
    "            display_text_with_box(frame, \"How it is going\", (300, 65), box_color=(0, 128, 0), text_color=(0, 255, 0))\n",
    "\n",
    "        # Draw shoulder points if pose detected.\n",
    "        if pose_results.pose_landmarks:\n",
    "            left_shoulder = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "            right_shoulder = pose_results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "            left_shoulder_coords = (int(left_shoulder.x * frame.shape[1]), int(left_shoulder.y * frame.shape[0]))\n",
    "            right_shoulder_coords = (int(right_shoulder.x * frame.shape[1]), int(right_shoulder.y * frame.shape[0]))\n",
    "            \n",
    "            # Draw shoulder points as red dots.\n",
    "            cv2.circle(frame, left_shoulder_coords, 4, DOT_COLOR, -1)\n",
    "            cv2.circle(frame, right_shoulder_coords, 4, DOT_COLOR, -1)\n",
    "            cv2.line(frame, left_shoulder_coords, right_shoulder_coords, LINE_COLOR, 1)\n",
    "        \n",
    "        # Display the final frame.\n",
    "        cv2.imshow(\"Enhanced Hand, Face, and Shoulder Tracking\", frame)\n",
    "        \n",
    "        # Exit on pressing 'q'.\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c77b96b8-2384-4fe2-9d59-e4747cbba380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbbfda7a-65b4-41e2-aa3d-462fdc0e08e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d46bc26-66a0-4f6a-9120-1f6ea4dabf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINE_COLOR = (0, 255, 0)  # Green for lines\n",
    "DOT_COLOR = (0, 0, 255)   # Red for dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e119f26-13e1-44bd-92e0-b96c532f6975",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACE_POINTS = [\n",
    "    10, 109, 338, 297, 332, 284, 251, 389, 356, 264, 24, 1, 2, 0, 17, 50,\n",
    "    52, 65, 55, 8, 9, 290, 309, 334, 297, 17, 36, 67, 21, 22, 221, 429, \n",
    "    426, 370, 393, 361, 278, 290, 306, 254, 328, 324, 11, 12, 13, 14, 15, \n",
    "    16, 206, 426, 457, 393, 164, 379, 355, 336, 13, 14\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395d242a-3a8c-479a-8376-632044ab55f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BODY_POINTS = [\n",
    "    mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.RIGHT_SHOULDER,\n",
    "    mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.RIGHT_ELBOW,\n",
    "    mp_pose.PoseLandmark.LEFT_WRIST, mp_pose.PoseLandmark.RIGHT_WRIST,\n",
    "    mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.RIGHT_HIP,\n",
    "    mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.RIGHT_KNEE,\n",
    "    mp_pose.PoseLandmark.LEFT_ANKLE, mp_pose.PoseLandmark.RIGHT_ANKLE\n",
    "] * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "864dfbbb-a6f4-40e5-b976-77f96485fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_both_hands_raised(hand_landmarks):\n",
    "    raised_hands = 0\n",
    "    for hand in hand_landmarks:\n",
    "        # Check if wrist is below index finger tip for raised hand.\n",
    "        if hand.landmark[mp_hands.HandLandmark.WRIST].y < hand.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y:\n",
    "            raised_hands += 1\n",
    "    return raised_hands == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e160f11-1100-4fe6-9d28-b40a9334526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_head_down(face_landmarks):\n",
    "    head_top = face_landmarks.landmark[10].y  # Top of head\n",
    "    nose_tip = face_landmarks.landmark[1].y   # Tip of nose\n",
    "    return (nose_tip - head_top) > 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d0fcc9a-2b37-4a9d-897d-578f022fb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hand_landmarks_custom(image, hand_landmarks):\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        hand_landmarks,\n",
    "        mp_hands.HAND_CONNECTIONS,\n",
    "        mp_drawing.DrawingSpec(color=LINE_COLOR, thickness=1, circle_radius=2),\n",
    "        mp_drawing.DrawingSpec(color=DOT_COLOR, thickness=3)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcb3d43f-0c09-4b83-99fe-1eaa06b3e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_face_mesh_custom(image, face_landmarks):\n",
    "    for i in range(len(FACE_POINTS) - 1):\n",
    "        start = face_landmarks.landmark[FACE_POINTS[i]]\n",
    "        end = face_landmarks.landmark[FACE_POINTS[i + 1]]\n",
    "        start_point = (int(start.x * image.shape[1]), int(start.y * image.shape[0]))\n",
    "        end_point = (int(end.x * image.shape[1]), int(end.y * image.shape[0]))\n",
    "        cv2.line(image, start_point, end_point, LINE_COLOR, 1)\n",
    "    \n",
    "    for idx in FACE_POINTS:\n",
    "        point = face_landmarks.landmark[idx]\n",
    "        point_coords = (int(point.x * image.shape[1]), int(point.y * image.shape[0]))\n",
    "        cv2.circle(image, point_coords, 2, DOT_COLOR, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aee5bfa-ebe0-4136-8e27-8faeb51445a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_body_landmarks_custom(image, pose_landmarks):\n",
    "    for point in BODY_POINTS:\n",
    "        coords = pose_landmarks.landmark[point]\n",
    "        point_coords = (int(coords.x * image.shape[1]), int(coords.y * image.shape[0]))\n",
    "        cv2.circle(image, point_coords, 2, DOT_COLOR, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3b86a8c-fe0a-44ab-ad86-014a6535f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_text_with_box(image, text, position, box_color=(50, 50, 50), text_color=(255, 255, 255)):\n",
    "    (text_width, text_height), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    box_coords = ((position[0] - 10, position[1] - 40), (position[0] + text_width + 10, position[1] + text_height - 10))\n",
    "    cv2.rectangle(image, box_coords[0], box_coords[1], box_color, cv2.FILLED)\n",
    "    cv2.putText(image, text, position, cv2.FONT_HERSHEY_SIMPLEX, 1, text_color, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b260968-0fc6-4457-b7e1-98d6fcd56676",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands, \\\n",
    "     mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5) as face_mesh, \\\n",
    "     mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)  # Mirror the frame.\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB.\n",
    "\n",
    "        # Process hands, face, and pose (for body).\n",
    "        hand_results = hands.process(rgb_frame)\n",
    "        face_results = face_mesh.process(rgb_frame)\n",
    "        pose_results = pose.process(rgb_frame)\n",
    "        \n",
    "        both_hands_raised = False\n",
    "        head_down = False\n",
    "        \n",
    "        # Draw face landmarks if detected.\n",
    "        if face_results.multi_face_landmarks:\n",
    "            for face_landmarks in face_results.multi_face_landmarks:\n",
    "                draw_face_mesh_custom(frame, face_landmarks)\n",
    "                head_down = is_head_down(face_landmarks)\n",
    "        \n",
    "        # Draw hand landmarks and check if both hands are raised.\n",
    "        if hand_results.multi_hand_landmarks:\n",
    "            both_hands_raised = are_both_hands_raised(hand_results.multi_hand_landmarks)\n",
    "            for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "                draw_hand_landmarks_custom(frame, hand_landmarks)\n",
    "        \n",
    "        # Draw body points for a technical, sophisticated look.\n",
    "        if pose_results.pose_landmarks:\n",
    "            draw_body_landmarks_custom(frame, pose_results.pose_landmarks)\n",
    "        \n",
    "        # Display messages based on hand and head positions.\n",
    "        if both_hands_raised:\n",
    "            display_text_with_box(frame, \"Feeling Good\", (20, 65), box_color=(50, 50, 50), text_color=(0, 255, 0))\n",
    "        elif head_down:\n",
    "            display_text_with_box(frame, \"Feeling Bad\", (20, 120), box_color=(50, 50, 50), text_color=(0, 0, 255))\n",
    "        \n",
    "        # Display the final frame.\n",
    "        cv2.imshow(\"Sophisticated Hand, Face, and Body Tracking\", frame)\n",
    "        \n",
    "        # Exit on pressing 'q'.\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d186498-d2fc-4170-9a9a-1536aa5d73c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackKernel",
   "language": "python",
   "name": "hackkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
